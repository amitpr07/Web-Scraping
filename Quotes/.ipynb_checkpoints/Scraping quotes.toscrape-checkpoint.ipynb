{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38a11fee",
   "metadata": {},
   "source": [
    "# Scraping quotes.toscrape.com\n",
    "  \n",
    " 1. Web scraping is the process of using tools to extract content and data from a website\n",
    " \n",
    " 3. The tools used in the project are Python programming language and the various libraries available in python namely:\n",
    "     - requests (to get webapge in http format) https://docs.python-requests.org/en/latest/\n",
    "     - Beautiful Soup 4 (to convert the html data into parsable form) https://beautiful-soup-4.readthedocs.io/en/latest/\n",
    "     - Pandas (to create a database of the scraped information and make a csv file) https://pandas.pydata.org/\n",
    "     - Regular Expressions 're' (makes dealing with expression and text easier) https://docs.python.org/3/library/re.html\n",
    "     - os (to use operating system based functions in our programs) https://docs.python.org/3/library/os.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c089d613",
   "metadata": {},
   "source": [
    "## Task Statement\n",
    "\n",
    "  - To scrape a 'https://quotes.toscrape.com' for the most common quote_tags and to get top 10 quotes from each tag\n",
    "  \n",
    "  - 'quotes.toscrape.com' is a free web scraping sandbox to help people practise web-scraping\n",
    "  \n",
    "  - We will output a CSV file containg all the quote tags and the links to top quotes in each tag\n",
    "  \n",
    "  - Then for each quote tag we will output a CSV file containg top 10 quotes along with the author name, about the author and other tags on the quote which we will store in a separate folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d38cdb",
   "metadata": {},
   "source": [
    "### The format for CSV file :\n",
    "\n",
    "   - for the Quotes.csv:\n",
    "\n",
    "        Quote Tag, URL\n",
    "        \n",
    "\n",
    "   - for the CSV files for each tag:\n",
    "   \n",
    "        Quote, Author, About the Author, Other tags\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479df72b",
   "metadata": {},
   "source": [
    "##### Scraping the homepage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4750a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_quotes(page_url):\n",
    "    \n",
    "    #get the page\n",
    "    response=requests.get(page_url)\n",
    "    \n",
    "    #check the status of response\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load home page {}'.format(page_url))\n",
    "    \n",
    "    #convert into BS4 for parsing\n",
    "    homepage_doc=BeautifulSoup(response.text,'html.parser')\n",
    "    \n",
    "    return homepage_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6e35de",
   "metadata": {},
   "source": [
    "returns the homepage in parsable form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cab8213",
   "metadata": {},
   "source": [
    "##### Getting the name of the top quote tags and their URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b5254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quoteurl(homepage_doc):\n",
    "    \n",
    "    #initializing lists\n",
    "    quote_names=[]\n",
    "    quote_webpage=[]\n",
    "    \n",
    "    #get tags of the quotes\n",
    "    ttags=homepage_doc.find_all('span',{'class':'tag-item'})\n",
    "    #get all the quote tags and url\n",
    "    for i in range(0,len(ttags)):\n",
    "        quote_names.append(ttags[i].text.strip())\n",
    "        quote_webpage.append('https://quotes.toscrape.com/'+ttags[i].a['href'])\n",
    "        \n",
    "    return [quote_names,quote_webpage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b829534",
   "metadata": {},
   "source": [
    "returns a list of quote tags and the urls "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5989ef84",
   "metadata": {},
   "source": [
    "#### Getting the url for each quote tag page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5493bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_details(quote_url):\n",
    "    \n",
    "    #get the page\n",
    "    res=requests.get(quote_url)\n",
    "    \n",
    "    #check the status of response\n",
    "    if res.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(quote_url))\n",
    "    \n",
    "    #convert into BS4 for parsing\n",
    "    quote_page_doc=BeautifulSoup(res.text,'html.parser')\n",
    "    \n",
    "    return quote_page_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19d31fe",
   "metadata": {},
   "source": [
    "returns the quote tag page in parsible form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f7371b",
   "metadata": {},
   "source": [
    "#### Getting the top quotes and other details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1578dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quote_details(quote_doc):\n",
    "    \n",
    "    #get all the quotes\n",
    "    quo_tags=quote_doc.find_all('div',{'class':'quote'})\n",
    "    \n",
    "    #initializing lists\n",
    "    quotes=[]\n",
    "    auth_name=[]\n",
    "    about_auth=[]\n",
    "    tags=[]\n",
    "    \n",
    "    #getting details\n",
    "    for i in range(0,len(quo_tags)):\n",
    "        quotes.append(quo_tags[i].find('span',{'class':'text'}).text.strip())\n",
    "        auth_name.append(quo_tags[i].find_all('span')[1].small.text.strip())\n",
    "        about_auth.append('https://quotes.toscrape.com/'+quo_tags[i].find_all('span')[1].a['href'])\n",
    "        #replacing ',' with ':' in between tags\n",
    "        t=':'.join(re.findall(r'[^, ]+',quo_tags[i].find_all('div',{'class':'tags'})[0].meta['content']))\n",
    "        tags.append(t)\n",
    "        \n",
    "    return [quotes,auth_name,about_auth,tags]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fbaa2e",
   "metadata": {},
   "source": [
    "returns the top quotes and their respective details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658be237",
   "metadata": {},
   "source": [
    "#### Writing all details to csv file using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1d67c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(url,quote_name):\n",
    "\n",
    "    #get the parser page\n",
    "    doc_parse=get_page_details(url)\n",
    "    \n",
    "    #get all the details in UPC, Name, Genre, Stars, Price, Availability, Description order\n",
    "    detail_list=get_quote_details(doc_parse)\n",
    "    \n",
    "    #creating directory to store data\n",
    "    os.makedirs('Data',exist_ok=True)\n",
    "    \n",
    "    #checking if file already exists in case of failures\n",
    "    fname='Data'+'/'+quote_name+'.csv'\n",
    "    if os.path.exists(fname):\n",
    "        print(\"The file {} already exists....Skipping\".format(fname))\n",
    "        return\n",
    "    \n",
    "    #create dataframe using pandas\n",
    "    dict2={'Quote':detail_list[0],\"Author\":detail_list[1],'About the Author':detail_list[2],'Other Tags':detail_list[3]}\n",
    "    df=pd.DataFrame(dict2)\n",
    "    \n",
    "    #creating CSV file\n",
    "    print(\"Creating {} .....\".format(fname))\n",
    "    df.to_csv(fname,index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b638885",
   "metadata": {},
   "source": [
    "writes all the informatiom about each quote tag to csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b796cb8",
   "metadata": {},
   "source": [
    "### The driver function to run the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71d9a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def driver():\n",
    "\n",
    "    url='https://quotes.toscrape.com/'\n",
    "    i=scrape_quotes(url)\n",
    "    the_lists=get_quoteurl(i)\n",
    "    \n",
    "    #create dataframe using pandas\n",
    "    dict1={'Quote Tag':the_lists[0],\"URL\":the_lists[1]}\n",
    "    df=pd.DataFrame(dict1,index=list(range(1,11)))\n",
    "\n",
    "    #create csv\n",
    "    if os.path.exists('Quotes.csv'):\n",
    "        print(\"The file {} already exists.....Skipping\".format('Quotes.csv'))\n",
    "    else:\n",
    "        print(\"Creating Quotes.csv .....\")\n",
    "        df.to_csv('Quotes.csv',index=None)\n",
    "    \n",
    "    #Scraping the quote webpages\n",
    "    for i in range(0,10):\n",
    "        print(\"Scraping {}\".format(the_lists[0][i]))\n",
    "        write_to_csv(the_lists[1][i],the_lists[0][i])\n",
    "        \n",
    "    print(\"Done!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a29a159",
   "metadata": {},
   "source": [
    "Drives the code by creating Quotes.csv and calling other functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65733cf",
   "metadata": {},
   "source": [
    "#### Run the driver to begin scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59046037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Quotes.csv .....\n",
      "Scraping love\n",
      "Creating Data/love.csv .....\n",
      "Scraping inspirational\n",
      "Creating Data/inspirational.csv .....\n",
      "Scraping life\n",
      "Creating Data/life.csv .....\n",
      "Scraping humor\n",
      "Creating Data/humor.csv .....\n",
      "Scraping books\n",
      "Creating Data/books.csv .....\n",
      "Scraping reading\n",
      "Creating Data/reading.csv .....\n",
      "Scraping friendship\n",
      "Creating Data/friendship.csv .....\n",
      "Scraping friends\n",
      "Creating Data/friends.csv .....\n",
      "Scraping truth\n",
      "Creating Data/truth.csv .....\n",
      "Scraping simile\n",
      "Creating Data/simile.csv .....\n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc7084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
